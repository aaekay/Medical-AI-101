{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Module 5A: Chest X-ray Problem Framing and Method Map\n## From Clinical Need to Candidate AI Approaches\n\n**Goal:** Start with a real chest X-ray problem, compare solution families, and build a non-deep-learning baseline before training a CNN."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Why this chapter first?\nBefore coding deep learning, clinicians should understand **what problem we are solving**, **which methods are available**, and **what baseline performance looks like**."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Learning objectives\n1. Define a clinically meaningful binary task in chest radiology.\n2. Compare rule-based, traditional ML, and deep learning options.\n3. Build a handcrafted-feature baseline on a real chest X-ray dataset.\n4. Understand why PR-AUC and ROC-AUC both matter.\n5. Prepare the handoff to deep-learning training in Module 5B."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 0: Clinical Problem\n**Problem statement:** At triage, can we flag chest X-rays likely to show pneumonia so radiologists can prioritize review?\n\nThis is a **binary classification** task:\n- Class 0: `NORMAL`\n- Class 1: `PNEUMONIA`\n\nClinical framing:\n- False negatives can delay treatment.\n- False positives increase workload.\n- The right threshold depends on the service context."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Run this cell once at the start. It auto-configures paths in Google Colab and does nothing harmful on local Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_repo_for_colab(\n",
    "    repo_url='https://github.com/aaekay/Medical-AI-101.git',\n",
    "    repo_dir='/content/Medical-AI-101',\n",
    "    notebook_dir='chapters',\n",
    "):\n",
    "    if 'google.colab' not in sys.modules:\n",
    "        print(f'Local runtime detected. Working directory: {Path.cwd()}')\n",
    "        return\n",
    "\n",
    "    repo_path = Path(repo_dir)\n",
    "    if not repo_path.exists():\n",
    "        print('Cloning Medical-AI-101 into /content ...')\n",
    "        subprocess.check_call(['git', 'clone', repo_url, str(repo_path)])\n",
    "\n",
    "    target = repo_path / notebook_dir\n",
    "    os.chdir(target)\n",
    "    print(f'Colab ready. Working directory: {Path.cwd()}')\n",
    "\n",
    "setup_repo_for_colab()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom IPython.display import display\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    average_precision_score,\n    confusion_matrix,\n    precision_recall_curve,\n    roc_auc_score,\n    roc_curve,\n)\n\ntry:\n    import ipywidgets as widgets\nexcept ImportError as exc:\n    raise ImportError('ipywidgets is required for interactive demos in Module 5A.') from exc\n\n\ndef resolve_cxr_root():\n    candidates = [\n        Path('../data/chest_xray_small'),\n        Path('data/chest_xray_small'),\n    ]\n    for cand in candidates:\n        if cand.exists():\n            return cand\n    return None\n\n\ndef build_manifest(root):\n    rows = []\n    for split in ['train', 'val', 'test']:\n        for label_name, label in [('NORMAL', 0), ('PNEUMONIA', 1)]:\n            folder = root / split / label_name\n            if not folder.exists():\n                continue\n            for p in sorted(folder.glob('*')):\n                if p.suffix.lower() in {'.jpeg', '.jpg', '.png'}:\n                    rows.append({'path': str(p), 'split': split, 'label_name': label_name, 'label': label})\n    return pd.DataFrame(rows)\n\n\nCXR_ROOT = resolve_cxr_root()\nif CXR_ROOT is None:\n    print('Dataset folder not found. Set it up first, then rerun this notebook.')\n    print('One-time command (from repo root): python scripts/setup_chest_xray_from_gdrive.py')\n    print('See: data/chest_xray_small/README.md')\n    manifest = pd.DataFrame(columns=['path', 'split', 'label_name', 'label'])\nelse:\n    manifest = build_manifest(CXR_ROOT)\n    print(f'Found chest X-ray root: {CXR_ROOT}')\n    print(f'Manifest rows: {len(manifest)}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if manifest.empty:\n    print('No images discovered yet. This notebook will still show the method map and setup logic.')\nelse:\n    display(manifest.head(10))\n    summary = (\n        manifest.groupby(['split', 'label_name'])\n        .size()\n        .rename('n_images')\n        .reset_index()\n    )\n    display(summary)\n\n    pivot = summary.pivot(index='split', columns='label_name', values='n_images').fillna(0)\n    ax = pivot.plot(kind='bar', figsize=(7, 3.6), color=['#4c78a8', '#e45756'])\n    ax.set_title('Class Balance by Split')\n    ax.set_ylabel('Images')\n    ax.tick_params(axis='x', rotation=0)\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Method Map (Top-Down)\nDifferent methods answer the same clinical question with different assumptions and trade-offs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "method_map = pd.DataFrame([\n    {\n        'Method family': 'Rule-based heuristics',\n        'How it works': 'Hand-written imaging rules (e.g., brightness zones, edge patterns)',\n        'Strength': 'Transparent and explainable',\n        'Limitation': 'Brittle; poor generalization to varied scans',\n        'Role in course': 'Conceptual baseline',\n    },\n    {\n        'Method family': 'Traditional ML on handcrafted features',\n        'How it works': 'Engineer features from images, then train logistic regression / tree',\n        'Strength': 'Fast on CPU; useful baseline',\n        'Limitation': 'Feature engineering limits performance ceiling',\n        'Role in course': 'Practical baseline in this notebook',\n    },\n    {\n        'Method family': 'Deep learning (CNNs)',\n        'How it works': 'Learn image features directly from pixels',\n        'Strength': 'High performance on visual tasks',\n        'Limitation': 'Needs more data, compute, and careful evaluation',\n        'Role in course': 'Main model in Module 5B',\n    },\n])\n\ndisplay(method_map)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: Visual Sanity Check\nInspect sample images from each class before modeling. This catches many pipeline mistakes early."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def show_class_examples(manifest_df, n_per_class=4, split='train', random_state=42):\n    subset = manifest_df[manifest_df['split'] == split].copy()\n    if subset.empty:\n        print(f'No rows found for split={split}.')\n        return\n\n    fig, axes = plt.subplots(2, n_per_class, figsize=(3 * n_per_class, 6))\n    labels = [('NORMAL', 0), ('PNEUMONIA', 1)]\n\n    for r, (label_name, label) in enumerate(labels):\n        group = subset[subset['label'] == label]\n        if group.empty:\n            for c in range(n_per_class):\n                axes[r, c].axis('off')\n            continue\n        sample = group.sample(n=min(n_per_class, len(group)), random_state=random_state)\n        for c in range(n_per_class):\n            axes[r, c].axis('off')\n            if c < len(sample):\n                img = Image.open(sample.iloc[c]['path']).convert('L')\n                axes[r, c].imshow(img, cmap='gray')\n                axes[r, c].set_title(label_name)\n\n    plt.tight_layout()\n    plt.show()\n\n\nif manifest.empty:\n    placeholder = Path('../assets/chest_xray_placeholder.png')\n    if not placeholder.exists():\n        placeholder = Path('assets/chest_xray_placeholder.png')\n    if placeholder.exists():\n        img = Image.open(placeholder).convert('L')\n        plt.figure(figsize=(4, 4))\n        plt.imshow(img, cmap='gray')\n        plt.title('Placeholder image (dataset not loaded)')\n        plt.axis('off')\n        plt.show()\n    else:\n        print('No dataset and no placeholder image found.')\nelse:\n    show_class_examples(manifest, n_per_class=4, split='train')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: Handcrafted Feature Baseline\nBefore CNNs, we build a lightweight baseline to anchor expectations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def extract_features(image_path, size=128):\n    img = Image.open(image_path).convert('L').resize((size, size))\n    arr = np.asarray(img, dtype=np.float32) / 255.0\n\n    # Simple handcrafted radiographic proxies for teaching.\n    mean_intensity = arr.mean()\n    std_intensity = arr.std()\n    p90 = np.percentile(arr, 90)\n    center = arr[size // 4 : 3 * size // 4, size // 4 : 3 * size // 4].mean()\n    periphery = np.concatenate([\n        arr[: size // 6, :].ravel(),\n        arr[-size // 6 :, :].ravel(),\n        arr[:, : size // 6].ravel(),\n        arr[:, -size // 6 :].ravel(),\n    ]).mean()\n    grad_x = np.abs(np.diff(arr, axis=1)).mean()\n    grad_y = np.abs(np.diff(arr, axis=0)).mean()\n    symmetry_gap = np.abs(arr - np.fliplr(arr)).mean()\n\n    return {\n        'mean_intensity': mean_intensity,\n        'std_intensity': std_intensity,\n        'p90': p90,\n        'center_intensity': center,\n        'periphery_intensity': periphery,\n        'edge_x': grad_x,\n        'edge_y': grad_y,\n        'symmetry_gap': symmetry_gap,\n    }\n\n\ndef make_feature_table(manifest_df):\n    rows = []\n    for _, row in manifest_df.iterrows():\n        feats = extract_features(row['path'])\n        feats.update({'split': row['split'], 'label': int(row['label']), 'path': row['path']})\n        rows.append(feats)\n    return pd.DataFrame(rows)\n\n\nif manifest.empty:\n    feature_df = pd.DataFrame()\n    print('Feature extraction skipped because dataset is not loaded.')\nelse:\n    feature_df = make_feature_table(manifest)\n    print(f'Feature rows: {len(feature_df)}')\n    display(feature_df.head())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if feature_df.empty:\n    baseline_test = pd.DataFrame()\n    print('Baseline training skipped: no feature table available.')\nelse:\n    train_df = feature_df[feature_df['split'].isin(['train', 'val'])].copy()\n    test_df = feature_df[feature_df['split'] == 'test'].copy()\n\n    feature_cols = [\n        'mean_intensity',\n        'std_intensity',\n        'p90',\n        'center_intensity',\n        'periphery_intensity',\n        'edge_x',\n        'edge_y',\n        'symmetry_gap',\n    ]\n\n    X_train = train_df[feature_cols].values\n    y_train = train_df['label'].values\n    X_test = test_df[feature_cols].values\n    y_test = test_df['label'].values\n\n    baseline_model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n    baseline_model.fit(X_train, y_train)\n\n    test_proba = baseline_model.predict_proba(X_test)[:, 1]\n    roc_auc = roc_auc_score(y_test, test_proba)\n    pr_auc = average_precision_score(y_test, test_proba)\n\n    print(f'Baseline ROC-AUC: {roc_auc:.3f}')\n    print(f'Baseline PR-AUC:  {pr_auc:.3f}')\n\n    baseline_test = test_df[['path', 'label']].copy()\n    baseline_test['probability'] = test_proba\n\n    out_path = (CXR_ROOT.parent if CXR_ROOT is not None else Path('../data')) / 'module_05a_baseline_test_predictions.csv'\n    baseline_test.to_csv(out_path, index=False)\n    print(f'Saved baseline predictions to {out_path}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Why PR and ROC?\n- **ROC-AUC**: Measures ranking quality across thresholds (TPR vs FPR).\n- **PR-AUC**: Focuses on positive class retrieval (precision vs recall), often more informative when positives are less frequent.\n- Use both, then pick thresholds based on workflow constraints."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if baseline_test.empty:\n    print('No baseline predictions available for curve plotting.')\nelse:\n    y_true = baseline_test['label'].values\n    proba = baseline_test['probability'].values\n\n    fpr, tpr, _ = roc_curve(y_true, proba)\n    precision, recall, _ = precision_recall_curve(y_true, proba)\n\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4.2))\n\n    axes[0].plot(fpr, tpr, color='#4c78a8', linewidth=2)\n    axes[0].plot([0, 1], [0, 1], '--', color='gray', linewidth=1)\n    axes[0].set_title(f'ROC Curve (AUC={roc_auc_score(y_true, proba):.2f})')\n    axes[0].set_xlabel('False Positive Rate')\n    axes[0].set_ylabel('True Positive Rate')\n\n    axes[1].plot(recall, precision, color='#e45756', linewidth=2)\n    axes[1].hlines(y_true.mean(), 0, 1, linestyles='--', color='gray', linewidth=1)\n    axes[1].set_title(f'PR Curve (AP={average_precision_score(y_true, proba):.2f})')\n    axes[1].set_xlabel('Recall')\n    axes[1].set_ylabel('Precision')\n\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def threshold_demo(threshold=0.50):\n    if baseline_test.empty:\n        print('No baseline predictions available.')\n        return\n\n    y_true = baseline_test['label'].values\n    proba = baseline_test['probability'].values\n    pred = (proba >= threshold).astype(int)\n    tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0, 1]).ravel()\n\n    precision = tp / (tp + fp) if (tp + fp) else 0.0\n    recall = tp / (tp + fn) if (tp + fn) else 0.0\n    specificity = tn / (tn + fp) if (tn + fp) else 0.0\n\n    print(f'Threshold: {threshold:.2f}')\n    print(f'Precision: {precision:.3f} | Recall: {recall:.3f} | Specificity: {specificity:.3f}')\n\n    counts = pd.Series({'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn})\n    fig, ax = plt.subplots(figsize=(6, 3.2))\n    ax.bar(counts.index, counts.values, color=['#54a24b', '#4c78a8', '#f58518', '#e45756'])\n    ax.set_title('Baseline Confusion Counts')\n    ax.set_ylabel('Images')\n    plt.tight_layout()\n    plt.show()\n\n\nwidgets.interact(\n    threshold_demo,\n    threshold=widgets.FloatSlider(value=0.50, min=0.05, max=0.95, step=0.05, description='Threshold', continuous_update=False),\n)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Wrap-up and Handoff to Module 5B\n- You framed the clinical problem first.\n- You compared method families before committing to deep learning.\n- You created a traditional ML baseline on real chest X-ray files.\n- Next: build and train a CNN with explicit label handling, train/val split checks, and hyperparameter controls."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
