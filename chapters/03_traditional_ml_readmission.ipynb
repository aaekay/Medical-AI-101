{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Module 3: First Clinical Prediction Model (Traditional ML)\n## Predicting 30-Day Readmission Risk\n\n**Goal:** Build, compare, and interpret two baseline models (Logistic Regression and Decision Tree)\nfor a clinically meaningful prediction task."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### How to use this notebook\n- Run cells top to bottom.\n- Keep notes on what changes model behavior.\n- This chapter introduces model training with small, reproducible steps."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Learning objectives\n1. Define features (`X`) and label (`y`) for a clinical prediction task.\n2. Train a baseline Logistic Regression model and Decision Tree model.\n3. Compare metrics that matter clinically, not just accuracy.\n4. Explore threshold trade-offs between sensitivity and specificity.\n5. Inspect model behavior and review missed high-risk patients."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 0: Clinical Problem\nAt discharge, a care team wants to identify patients at high risk of 30-day readmission.\nThe team can only intervene for a limited number of patients, so false negatives and false positives\nhave different operational consequences."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom IPython.display import display\n\ntry:\n    import ipywidgets as widgets\nexcept ImportError as exc:\n    raise ImportError('ipywidgets is required for the threshold demo.') from exc\n\ndef resolve_data_path(filename):\n    candidates = [Path('../data') / filename, Path('data') / filename]\n    for cand in candidates:\n        if cand.exists():\n            return cand\n    raise FileNotFoundError(f'Could not locate {filename} in ../data or data/')\n\nDATA_PATH = resolve_data_path('module_02_cleaned_for_module_03.csv')\ndf = pd.read_csv(DATA_PATH)\nprint(f'Loaded {len(df)} rows and {df.shape[1]} columns from {DATA_PATH}.')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "display(df.head(8))\nprint()\nprint('Class balance:')\nprint(df['label_readmit_30d'].value_counts(normalize=True).rename('proportion').round(3))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Define Features and Split Data\nWe use only information available by discharge time."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "id_col = 'encounter_id'\ntarget_col = 'label_readmit_30d'\n\nnumeric_features = [\n    'age',\n    'sex_female',\n    'sbp',\n    'ldl_mg_dl',\n    'smoke',\n    'comorbidity_count',\n    'prior_admissions_12m',\n]\ncategorical_features = ['insurance_type', 'race_group']\nfeature_cols = numeric_features + categorical_features\n\nX = df[feature_cols].copy()\ny = df[target_col].astype(int).copy()\nencounter_ids = df[id_col].copy()\n\nX_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n    X,\n    y,\n    encounter_ids,\n    test_size=0.25,\n    random_state=42,\n    stratify=y,\n)\n\nprint(f'Train rows: {len(X_train)}')\nprint(f'Test rows: {len(X_test)}')\nprint(f'Train prevalence: {y_train.mean():.3f}')\nprint(f'Test prevalence: {y_test.mean():.3f}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: Train Baseline Models\nModel A: Logistic Regression (linear, interpretable coefficients).\n\nModel B: Decision Tree (rule-like, nonlinear splits)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lr_preprocess = ColumnTransformer([\n    ('num', StandardScaler(), numeric_features),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n])\n\ntree_preprocess = ColumnTransformer([\n    ('num', 'passthrough', numeric_features),\n    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n])\n\nlr_model = Pipeline([\n    ('prep', lr_preprocess),\n    ('clf', LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)),\n])\n\ntree_model = Pipeline([\n    ('prep', tree_preprocess),\n    ('clf', DecisionTreeClassifier(max_depth=4, min_samples_leaf=5, random_state=42)),\n])\n\nlr_model.fit(X_train, y_train)\ntree_model.fit(X_train, y_train)\n\nlr_proba = lr_model.predict_proba(X_test)[:, 1]\ntree_proba = tree_model.predict_proba(X_test)[:, 1]\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def metrics_from_proba(y_true, proba, threshold=0.5):\n    pred = (proba >= threshold).astype(int)\n    tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0, 1]).ravel()\n\n    total = tp + tn + fp + fn\n    accuracy = (tp + tn) / total if total else np.nan\n    precision = tp / (tp + fp) if (tp + fp) else np.nan\n    recall = tp / (tp + fn) if (tp + fn) else np.nan\n    specificity = tn / (tn + fp) if (tn + fp) else np.nan\n    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else np.nan\n    auc = roc_auc_score(y_true, proba)\n\n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall_sensitivity': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'roc_auc': auc,\n        'tp': tp,\n        'tn': tn,\n        'fp': fp,\n        'fn': fn,\n    }\n\nlr_metrics = metrics_from_proba(y_test, lr_proba, threshold=0.5)\ntree_metrics = metrics_from_proba(y_test, tree_proba, threshold=0.5)\n\ncomparison = pd.DataFrame([lr_metrics, tree_metrics], index=['Logistic Regression', 'Decision Tree'])\ndisplay(comparison[['accuracy', 'precision', 'recall_sensitivity', 'specificity', 'f1', 'roc_auc']].round(3))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: Confusion Matrix View at Threshold 0.5\nConfusion counts make the clinical trade-offs concrete."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_confusion_counts(metrics, title):\n    counts = pd.Series({\n        'TP': metrics['tp'],\n        'TN': metrics['tn'],\n        'FP': metrics['fp'],\n        'FN': metrics['fn'],\n    })\n    fig, ax = plt.subplots(figsize=(5.8, 3.3))\n    ax.bar(counts.index, counts.values, color=['#54a24b', '#4c78a8', '#f58518', '#e45756'])\n    ax.set_title(title)\n    ax.set_ylabel('Patients')\n    plt.tight_layout()\n    plt.show()\n\nplot_confusion_counts(lr_metrics, 'Logistic Regression @ 0.50 threshold')\nplot_confusion_counts(tree_metrics, 'Decision Tree @ 0.50 threshold')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Interactive Threshold Tuning (Logistic Regression)\nLower thresholds usually increase sensitivity (catch more true readmissions) but can increase false positives."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def threshold_demo(threshold=0.50):\n    m = metrics_from_proba(y_test, lr_proba, threshold=threshold)\n    print(f'Threshold: {threshold:.2f}')\n    print(\n        f\"Accuracy: {m['accuracy']:.3f} | Precision: {m['precision']:.3f} | \"\n        f\"Sensitivity: {m['recall_sensitivity']:.3f} | Specificity: {m['specificity']:.3f}\"\n    )\n\n    fig, ax = plt.subplots(figsize=(5.8, 3.3))\n    labels = ['TP', 'TN', 'FP', 'FN']\n    values = [m['tp'], m['tn'], m['fp'], m['fn']]\n    colors = ['#54a24b', '#4c78a8', '#f58518', '#e45756']\n    ax.bar(labels, values, color=colors)\n    ax.set_title('Logistic Regression Confusion Counts')\n    ax.set_ylabel('Patients')\n    plt.tight_layout()\n    plt.show()\n\nwidgets.interact(\n    threshold_demo,\n    threshold=widgets.FloatSlider(\n        value=0.50, min=0.10, max=0.90, step=0.05, description='Threshold', continuous_update=False\n    ),\n)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 5: Model Interpretation\nLogistic Regression coefficients show directional influence.\n\nDecision Trees show path-based logic."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lr_feature_names = lr_model.named_steps['prep'].get_feature_names_out()\nlr_coefs = lr_model.named_steps['clf'].coef_[0]\ncoef_table = pd.DataFrame({'feature': lr_feature_names, 'coefficient': lr_coefs})\ncoef_table['abs_coefficient'] = coef_table['coefficient'].abs()\ncoef_table = coef_table.sort_values('abs_coefficient', ascending=False)\n\ndisplay(coef_table[['feature', 'coefficient']].head(12).round(3))\n\ntop10 = coef_table.head(10).iloc[::-1]\nfig, ax = plt.subplots(figsize=(7, 4))\nax.barh(top10['feature'], top10['coefficient'], color='#4c78a8')\nax.axvline(0, color='black', linewidth=1)\nax.set_title('Top Logistic Coefficients (standardized scale)')\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tree_feature_names = tree_model.named_steps['prep'].get_feature_names_out()\nfig, ax = plt.subplots(figsize=(15, 6))\nplot_tree(\n    tree_model.named_steps['clf'],\n    feature_names=tree_feature_names,\n    class_names=['No readmit', 'Readmit'],\n    filled=True,\n    max_depth=2,\n    ax=ax,\n)\nax.set_title('Decision Tree (first 2 levels)')\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 6: Error Analysis - Who Did We Miss?\nFocus on false negatives because missed high-risk patients may not receive interventions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "pred_df = X_test.copy()\npred_df['encounter_id'] = ids_test.values\npred_df['actual_readmit_30d'] = y_test.values\npred_df['lr_probability'] = lr_proba\npred_df['lr_pred_0_50'] = (lr_proba >= 0.50).astype(int)\npred_df['tree_probability'] = tree_proba\npred_df['tree_pred_0_50'] = (tree_proba >= 0.50).astype(int)\n\nfalse_negatives = pred_df[(pred_df['actual_readmit_30d'] == 1) & (pred_df['lr_pred_0_50'] == 0)].copy()\nfalse_negatives = false_negatives.sort_values('lr_probability', ascending=True)\n\nprint(f'False negatives (Logistic Regression @ 0.50): {len(false_negatives)}')\ndisplay(false_negatives[['encounter_id', 'age', 'sbp', 'ldl_mg_dl', 'smoke', 'comorbidity_count', 'prior_admissions_12m', 'lr_probability']].head(10).round(3))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 7: Save Predictions for Module 4\nModule 4 will go deeper into evaluation and threshold policy decisions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "out_path = DATA_PATH.parent / 'module_03_test_predictions.csv'\npred_df[['encounter_id', 'actual_readmit_30d', 'lr_probability', 'lr_pred_0_50', 'tree_probability', 'tree_pred_0_50']]    .to_csv(out_path, index=False)\n\nprint(f'Saved test prediction file to {out_path}')\ndisplay(pred_df.head(8).round(3))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Wrap-up: Key Takeaways\n- You trained your first two baseline clinical prediction models.\n- Accuracy alone is not enough in medicine; sensitivity/specificity trade-offs matter.\n- Threshold policy can change who gets flagged for intervention.\n- Error analysis helps identify where the model may fail clinically.\n- In Module 4, we will formalize evaluation beyond a single threshold."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}