{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Module 5B: Labels, Splits, and Deep Learning Training\n## Building a Chest X-ray CNN End to End\n\n**Goal:** Move from problem framing to a trainable CNN workflow with real image files, clean split logic, and reproducible experiments."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Learning objectives\n1. Validate folder-based labels and inspect subtype artifacts in filenames.\n2. Build a CPU-friendly subset from a real chest X-ray dataset.\n3. Create PyTorch datasets and dataloaders without hidden magic.\n4. Train a compact CNN and track ROC-AUC + PR-AUC on validation data.\n5. Run small hyperparameter experiments and save outputs for Module 5C."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 0: Dataset Choice and Setup\nRecommended dataset: **Chest X-Ray Images (Pneumonia)** (Kermany et al.).\n\nExpected structure:\n- `data/chest_xray_small/train/NORMAL`, `.../train/PNEUMONIA`\n- `data/chest_xray_small/val/NORMAL`, `.../val/PNEUMONIA`\n- `data/chest_xray_small/test/NORMAL`, `.../test/PNEUMONIA`\n\nIf your dataset is larger, this notebook downsamples to a balanced subset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport time\nimport copy\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nfrom IPython.display import display\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.metrics import average_precision_score, roc_auc_score\n\ntry:\n    import ipywidgets as widgets\nexcept ImportError as exc:\n    raise ImportError('ipywidgets is required for Module 5B interactive controls.') from exc\n\n\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n\n\nset_seed(42)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device:', device)\n\n\ndef resolve_cxr_root():\n    candidates = [Path('../data/chest_xray_small'), Path('data/chest_xray_small')]\n    for cand in candidates:\n        if cand.exists():\n            return cand\n    return None\n\n\ndef build_manifest(root):\n    rows = []\n    for split in ['train', 'val', 'test']:\n        for label_name, label in [('NORMAL', 0), ('PNEUMONIA', 1)]:\n            folder = root / split / label_name\n            if not folder.exists():\n                continue\n            for p in sorted(folder.glob('*')):\n                if p.suffix.lower() in {'.jpeg', '.jpg', '.png'}:\n                    rows.append({'path': str(p), 'split': split, 'label_name': label_name, 'label': label})\n    return pd.DataFrame(rows)\n\n\nCXR_ROOT = resolve_cxr_root()\nif CXR_ROOT is None:\n    DATA_READY = False\n    manifest = pd.DataFrame(columns=['path', 'split', 'label_name', 'label'])\n    print('Dataset not found. Add files under data/chest_xray_small and rerun.')\n    print('See setup notes in data/chest_xray_small/README.md')\nelse:\n    DATA_READY = True\n    manifest = build_manifest(CXR_ROOT)\n    print(f'Loaded manifest with {len(manifest)} rows from {CXR_ROOT}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not DATA_READY or manifest.empty:\n    print('No manifest to inspect yet.')\nelse:\n    display(manifest.head(8))\n\n    counts = manifest.groupby(['split', 'label_name']).size().rename('n_images').reset_index()\n    display(counts)\n\n    pivot = counts.pivot(index='split', columns='label_name', values='n_images').fillna(0)\n    ax = pivot.plot(kind='bar', figsize=(7, 3.5), color=['#4c78a8', '#e45756'])\n    ax.set_title('Raw Class Balance by Split')\n    ax.set_ylabel('Images')\n    ax.tick_params(axis='x', rotation=0)\n    plt.tight_layout()\n    plt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 1: Label Audit\nEven with folder labels, inspect filenames for potential subtype hints (e.g., bacterial vs viral).\nThis helps plan future multi-label or multi-class extensions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if not DATA_READY or manifest.empty:\n    print('Label audit skipped: dataset missing.')\nelse:\n    lower_path = manifest['path'].str.lower()\n    manifest['pneumonia_subtype_hint'] = np.where(\n        manifest['label_name'] == 'PNEUMONIA',\n        np.where(lower_path.str.contains('virus'), 'virus', np.where(lower_path.str.contains('bacteria'), 'bacteria', 'unspecified')),\n        'normal',\n    )\n\n    subtype_counts = (\n        manifest[manifest['label_name'] == 'PNEUMONIA']\n        .groupby(['split', 'pneumonia_subtype_hint'])\n        .size()\n        .rename('n_images')\n        .reset_index()\n    )\n    display(subtype_counts)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 2: Build a Balanced, CPU-Friendly Subset\nTarget subset per class (modifiable):\n- Train: up to 600\n- Val: up to 150\n- Test: up to 150\n\nBalanced subsets make teaching and debugging easier."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def build_balanced_subset(manifest_df, per_class=None, random_state=42):\n    if per_class is None:\n        per_class = {'train': 600, 'val': 150, 'test': 150}\n\n    sampled = []\n    for split, target in per_class.items():\n        for label in [0, 1]:\n            group = manifest_df[(manifest_df['split'] == split) & (manifest_df['label'] == label)]\n            if group.empty:\n                continue\n            take = min(target, len(group))\n            sampled.append(group.sample(n=take, random_state=random_state))\n\n    if not sampled:\n        return pd.DataFrame(columns=manifest_df.columns)\n\n    out = pd.concat(sampled, ignore_index=True)\n    return out.sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n\n\nif not DATA_READY or manifest.empty:\n    subset_manifest = pd.DataFrame(columns=manifest.columns)\n    print('Subset creation skipped: dataset missing.')\nelse:\n    subset_manifest = build_balanced_subset(manifest)\n    display(\n        subset_manifest.groupby(['split', 'label_name'])\n        .size()\n        .rename('n_images')\n        .reset_index()\n    )\n\n    out_dir = CXR_ROOT.parent\n    subset_manifest.to_csv(out_dir / 'module_05_manifest_subset.csv', index=False)\n    for split in ['train', 'val', 'test']:\n        subset_manifest[subset_manifest['split'] == split].to_csv(out_dir / f'module_05_{split}_manifest.csv', index=False)\n    print(f'Saved subset manifests in {out_dir}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 3: PyTorch Dataset and DataLoader\nWe avoid hidden abstractions and implement a small custom dataset class."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class ChestXrayDataset(Dataset):\n    def __init__(self, frame, img_size=224, augment=False):\n        self.frame = frame.reset_index(drop=True)\n        self.img_size = img_size\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.frame)\n\n    def __getitem__(self, idx):\n        row = self.frame.iloc[idx]\n        img = Image.open(row['path']).convert('L').resize((self.img_size, self.img_size))\n        arr = np.asarray(img, dtype=np.float32) / 255.0\n\n        if self.augment and np.random.rand() < 0.5:\n            arr = np.fliplr(arr).copy()\n\n        tensor = torch.from_numpy(arr).unsqueeze(0)\n\n        # Fixed normalization for teaching simplicity.\n        tensor = (tensor - 0.5) / 0.25\n\n        label = torch.tensor(float(row['label']), dtype=torch.float32)\n        return tensor, label, row['path']\n\n\ndef make_loaders(subset_df, batch_size=16, img_size=224):\n    train_df = subset_df[subset_df['split'] == 'train'].copy()\n    val_df = subset_df[subset_df['split'] == 'val'].copy()\n    test_df = subset_df[subset_df['split'] == 'test'].copy()\n\n    train_ds = ChestXrayDataset(train_df, img_size=img_size, augment=True)\n    val_ds = ChestXrayDataset(val_df, img_size=img_size, augment=False)\n    test_ds = ChestXrayDataset(test_df, img_size=img_size, augment=False)\n\n    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader\n\n\nif subset_manifest.empty:\n    print('DataLoader setup pending dataset availability.')\nelse:\n    train_loader, val_loader, test_loader = make_loaders(subset_manifest, batch_size=16, img_size=224)\n    xb, yb, _ = next(iter(train_loader))\n    print('Batch tensor shape:', tuple(xb.shape), '| labels shape:', tuple(yb.shape))\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 4: Define a Compact CNN\nThis network is intentionally small so students can train on CPU."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class SmallCXRNet(nn.Module):\n    def __init__(self, dropout=0.3):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 28 * 28, 128),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        return self.classifier(x).squeeze(1)\n\n\nmodel = SmallCXRNet(dropout=0.3)\nprint(model)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 5: Training and Validation Loops\nTrack both loss and ranking metrics (ROC-AUC, PR-AUC) each epoch."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_model(model, loader, criterion):\n    model.eval()\n    losses = []\n    all_probs = []\n    all_labels = []\n    all_paths = []\n\n    with torch.no_grad():\n        for xb, yb, paths in loader:\n            xb = xb.to(device)\n            yb = yb.to(device)\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            probs = torch.sigmoid(logits)\n\n            losses.append(loss.item())\n            all_probs.extend(probs.cpu().numpy().tolist())\n            all_labels.extend(yb.cpu().numpy().tolist())\n            all_paths.extend(paths)\n\n    y_true = np.array(all_labels, dtype=int)\n    y_prob = np.array(all_probs, dtype=float)\n\n    roc_auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.0\n    pr_auc = average_precision_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else 0.0\n\n    return {\n        'loss': float(np.mean(losses)) if losses else np.nan,\n        'roc_auc': float(roc_auc),\n        'pr_auc': float(pr_auc),\n        'y_true': y_true,\n        'y_prob': y_prob,\n        'paths': all_paths,\n    }\n\n\ndef train_model(train_loader, val_loader, learning_rate=1e-3, weight_decay=1e-4, dropout=0.3, epochs=5):\n    model = SmallCXRNet(dropout=dropout).to(device)\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n    history_rows = []\n    best_state = None\n    best_val_pr = -1.0\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        train_losses = []\n\n        for xb, yb, _ in train_loader:\n            xb = xb.to(device)\n            yb = yb.to(device)\n\n            optimizer.zero_grad()\n            logits = model(xb)\n            loss = criterion(logits, yb)\n            loss.backward()\n            optimizer.step()\n\n            train_losses.append(loss.item())\n\n        val_result = evaluate_model(model, val_loader, criterion)\n        train_loss = float(np.mean(train_losses)) if train_losses else np.nan\n\n        history_rows.append({\n            'epoch': epoch,\n            'train_loss': train_loss,\n            'val_loss': val_result['loss'],\n            'val_roc_auc': val_result['roc_auc'],\n            'val_pr_auc': val_result['pr_auc'],\n        })\n\n        print(\n            f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} \"\n            f\"| val_loss={val_result['loss']:.4f} | val_roc_auc={val_result['roc_auc']:.3f} \"\n            f\"| val_pr_auc={val_result['pr_auc']:.3f}\"\n        )\n\n        if val_result['pr_auc'] > best_val_pr:\n            best_val_pr = val_result['pr_auc']\n            best_state = copy.deepcopy(model.state_dict())\n\n    history = pd.DataFrame(history_rows)\n    if best_state is not None:\n        model.load_state_dict(best_state)\n\n    return model, history\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 6: Interactive Hyperparameter Runs\nUse `Run Interact` to launch a short experiment.\nSaved artifacts:\n- `data/module_05b_training_history.csv`\n- `data/module_05b_val_predictions.csv`\n- `data/module_05b_test_predictions.csv`\n- `data/module_05b_best_model.pt`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def save_predictions_csv(path, eval_dict):\n    out = pd.DataFrame({\n        'path': eval_dict['paths'],\n        'label': eval_dict['y_true'],\n        'probability': eval_dict['y_prob'],\n    })\n    out.to_csv(path, index=False)\n\n\ndef run_experiment(batch_size=16, img_size=224, learning_rate=1e-3, weight_decay=1e-4, dropout=0.3, epochs=5, seed=42):\n    if subset_manifest.empty:\n        print('No dataset available. Add chest X-ray files first.')\n        return\n\n    set_seed(seed)\n    train_loader, val_loader, test_loader = make_loaders(subset_manifest, batch_size=int(batch_size), img_size=int(img_size))\n\n    start = time.time()\n    model, history = train_model(\n        train_loader,\n        val_loader,\n        learning_rate=float(learning_rate),\n        weight_decay=float(weight_decay),\n        dropout=float(dropout),\n        epochs=int(epochs),\n    )\n    elapsed = time.time() - start\n\n    criterion = nn.BCEWithLogitsLoss()\n    val_eval = evaluate_model(model, val_loader, criterion)\n    test_eval = evaluate_model(model, test_loader, criterion)\n\n    run_id = f\"run_bs{batch_size}_lr{learning_rate}_do{dropout}_ep{epochs}_seed{seed}\"\n\n    history = history.copy()\n    history['run_id'] = run_id\n    history['batch_size'] = int(batch_size)\n    history['img_size'] = int(img_size)\n    history['learning_rate'] = float(learning_rate)\n    history['weight_decay'] = float(weight_decay)\n    history['dropout'] = float(dropout)\n    history['epochs'] = int(epochs)\n    history['elapsed_sec'] = float(elapsed)\n\n    out_dir = CXR_ROOT.parent if CXR_ROOT is not None else Path('../data')\n    hist_path = out_dir / 'module_05b_training_history.csv'\n    val_path = out_dir / 'module_05b_val_predictions.csv'\n    test_path = out_dir / 'module_05b_test_predictions.csv'\n    model_path = out_dir / 'module_05b_best_model.pt'\n\n    if hist_path.exists():\n        prev = pd.read_csv(hist_path)\n        all_hist = pd.concat([prev, history], ignore_index=True)\n    else:\n        all_hist = history\n    all_hist.to_csv(hist_path, index=False)\n\n    save_predictions_csv(val_path, val_eval)\n    save_predictions_csv(test_path, test_eval)\n    torch.save({'model_state_dict': model.state_dict(), 'run_id': run_id}, model_path)\n\n    print(f'Run ID: {run_id}')\n    print(f'Training time: {elapsed:.1f} sec')\n    print(f'Validation ROC-AUC: {val_eval[\"roc_auc\"]:.3f} | PR-AUC: {val_eval[\"pr_auc\"]:.3f}')\n    print(f'Test ROC-AUC:       {test_eval[\"roc_auc\"]:.3f} | PR-AUC: {test_eval[\"pr_auc\"]:.3f}')\n    print(f'Saved history to: {hist_path}')\n    print(f'Saved test predictions to: {test_path}')\n\n    fig, ax = plt.subplots(figsize=(7, 3.5))\n    ax.plot(history['epoch'], history['train_loss'], marker='o', label='Train loss')\n    ax.plot(history['epoch'], history['val_loss'], marker='o', label='Val loss')\n    ax.set_title('Loss Curves')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss')\n    ax.legend()\n    plt.tight_layout()\n    plt.show()\n\n\nwidgets.interact_manual(\n    run_experiment,\n    batch_size=widgets.IntSlider(value=16, min=8, max=32, step=8, description='Batch'),\n    img_size=widgets.IntSlider(value=224, min=128, max=256, step=32, description='Img'),\n    learning_rate=widgets.FloatLogSlider(value=1e-3, base=10, min=-4, max=-2, step=0.2, description='LR'),\n    weight_decay=widgets.FloatLogSlider(value=1e-4, base=10, min=-6, max=-3, step=0.2, description='WD'),\n    dropout=widgets.FloatSlider(value=0.3, min=0.0, max=0.6, step=0.1, description='Dropout'),\n    epochs=widgets.IntSlider(value=5, min=2, max=10, step=1, description='Epochs'),\n    seed=widgets.IntSlider(value=42, min=1, max=999, step=1, description='Seed'),\n)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Section 7: Recommended Starter Runs\nTry these runs in order:\n1. `batch=16`, `lr=1e-3`, `dropout=0.3`, `epochs=5`\n2. `batch=16`, `lr=5e-4`, `dropout=0.3`, `epochs=8`\n3. `batch=32`, `lr=1e-3`, `dropout=0.2`, `epochs=6`\n\nThen compare results in Module 5C."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Wrap-up and Handoff to Module 5C\n- You validated labels and dataset splits.\n- You trained a compact CNN and tracked validation PR-AUC/ROC-AUC.\n- You saved prediction files and training logs.\n- Next: choose thresholds, compare PR vs ROC in context, and pick operating points using policy constraints."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}